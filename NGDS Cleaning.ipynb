{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f330ecc4-ad97-44c3-8611-d2fb952c0c27",
   "metadata": {},
   "source": [
    "# NGDS Cleaning and Zone Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa3ac9-9eec-4007-bc24-616a673ce685",
   "metadata": {},
   "source": [
    "This script processes raw TRANSCOM data by using various sources to assign zones to the data, then cleans the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7a28c-8e4f-40d7-a5ab-cb2bd0c743b4",
   "metadata": {},
   "source": [
    "# Imports & Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe10f5-2fd5-4326-8751-c0fe3b183795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine, Unit\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QHBoxLayout, QPushButton, QComboBox\n",
    "import os\n",
    "\n",
    "#Get the absolute path of the folder where this script is located\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    "\n",
    "#Define the input and output directories\n",
    "input_dir = os.path.join(script_dir, \"Input\")\n",
    "output_dir = os.path.join(script_dir, \"Output\")\n",
    "\n",
    "#Ensure both directories exist\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4621b-ce9a-49d3-b981-90588c13b97f",
   "metadata": {},
   "source": [
    "Due to the collective size of this data, only three months of data can be cleaned and processed at one time.\n",
    "\n",
    "Raw NGDS data files should be:\n",
    "1. Located inside the \"Input\" folder within this \"Cleaning Script\" folder\n",
    "2. Formatted as a .txt file\n",
    "3. Titled using the following format: \"NGDS [Month] [Year]\" -- (Examples: \"NGDS June 2024\" or \"NGDS April 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314e8ed-386e-4e49-8119-6171bd17839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the absolute path of the script's directory\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    "\n",
    "#Define Input and Output directories\n",
    "input_dir = os.path.join(script_dir, \"Input\")\n",
    "output_dir = os.path.join(script_dir, \"Output\")\n",
    "\n",
    "#Ensure both directories exist\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#Global variable to store the output filename\n",
    "data = None\n",
    "output_filename = \"\"\n",
    "\n",
    "class MonthYearSelector(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Select Months and Years to Load\")\n",
    "        self.setGeometry(400, 400, 500, 250)\n",
    "        self.setWindowFlags(self.windowFlags())\n",
    "        self.activateWindow()\n",
    "        self.raise_()\n",
    "\n",
    "\n",
    "        #Available months and years\n",
    "        self.available_months = [\n",
    "            \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "            \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
    "        ]\n",
    "        self.available_years = [\"2023\", \"2024\", \"2025\", \"2026\", \"2027\"]\n",
    "\n",
    "        #Layout\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        #Month-Year Selection Rows\n",
    "        self.month_year_selections = []\n",
    "        for i in range(3):\n",
    "            row_layout = QHBoxLayout()\n",
    "\n",
    "            # Month Dropdown\n",
    "            month_dropdown = QComboBox()\n",
    "            month_dropdown.addItems([\"\"] + self.available_months)\n",
    "            month_dropdown.setFixedWidth(150)\n",
    "\n",
    "            # Year Dropdown\n",
    "            year_dropdown = QComboBox()\n",
    "            year_dropdown.addItems([\"\"] + self.available_years)\n",
    "            year_dropdown.setFixedWidth(80)\n",
    "\n",
    "            row_layout.addWidget(QLabel(f\"Select Month {i+1}:\"))\n",
    "            row_layout.addWidget(month_dropdown)\n",
    "            row_layout.addWidget(QLabel(\"Year:\"))\n",
    "            row_layout.addWidget(year_dropdown)\n",
    "\n",
    "            self.month_year_selections.append((month_dropdown, year_dropdown))\n",
    "            layout.addLayout(row_layout)\n",
    "\n",
    "        #Load Data Button\n",
    "        self.load_button = QPushButton(\"Load Data\")\n",
    "        self.load_button.clicked.connect(self.load_data)\n",
    "        layout.addWidget(self.load_button)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Loads selected months and years into a DataFrame.\"\"\"\n",
    "        global data, output_filename  # Ensure variables are accessible\n",
    "\n",
    "        selected_files = []\n",
    "        selected_months_years = []  # Store selected months and years for naming the file\n",
    "\n",
    "        for month_dropdown, year_dropdown in self.month_year_selections:\n",
    "            month = month_dropdown.currentText()\n",
    "            year = year_dropdown.currentText()\n",
    "\n",
    "            if month and year:\n",
    "                file_name = f\"NGDS {month} {year}.txt\"\n",
    "                file_path = os.path.join(input_dir, file_name)  # Read from Input folder\n",
    "                selected_files.append(file_path)\n",
    "                selected_months_years.append((month, year))  # Store for naming\n",
    "\n",
    "        if not selected_files:\n",
    "            print(\"Please select at least one month and year.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Loading data from: {', '.join(selected_files)}...\")\n",
    "\n",
    "        # Load and concatenate selected months\n",
    "        data_frames = []\n",
    "        for file_path in selected_files:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, delimiter=\"|\", low_memory=True)\n",
    "                data_frames.append(df)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: {file_path} not found. Skipping...\")\n",
    "\n",
    "        if not data_frames:\n",
    "            print(\"No valid data files found. Exiting...\")\n",
    "            return\n",
    "\n",
    "        data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "        # Generate the filename dynamically (but don't save yet)\n",
    "        unique_years = sorted(set(year for _, year in selected_months_years))  # Get unique years\n",
    "        month_abbr = [month[:3] for month, _ in selected_months_years]  # Convert months to short form\n",
    "        output_filename = f\"ClnNGDS_{'-'.join(month_abbr)}_{'-'.join(unique_years)}.csv\"\n",
    "\n",
    "        print(f\"Data successfully loaded. The file will be saved as '{output_filename}' in the Output folder at the end of the script.\")\n",
    "\n",
    "        self.close()  # Close the GUI window once data is loaded\n",
    "\n",
    "# Launch the GUI\n",
    "def launch_gui():\n",
    "    app = QApplication(sys.argv)\n",
    "    window = MonthYearSelector()\n",
    "    window.show()\n",
    "    app.exec_()\n",
    "\n",
    "# Run the GUI\n",
    "launch_gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b246aa-5721-4bf1-bbd5-3701ef1360f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleaning and Filtering\n",
    "\n",
    "#Dropping columns that are not needed\n",
    "cols_to_drop = [\n",
    "    'SHIPPING_AGENCY_RPT_LVL', 'SHIPPING_AGENCY_LVL_1','SHIPPING_AGENCY_LVL_2','BILL_OF_LADING',\n",
    "    'CONTRACT_TYPE','TPPS_DOCUMENT_ID','PURCHASE_ORDER_SHIPMENT_ID','RATE_PROFILE_ID','SERVICE_LVL_MODE',\n",
    "    'SERVICE_LVL_SPEED','SERVICE_LVL_DLVY_TM','COMMITTED_DELIVERY_DATE', 'SHIPPER_COUNTRY',\n",
    "    'SHIPPER_COUNTRY_CODE', 'SHIPPER_NGDS_THEATER', 'SHIPPER_NGDS_REGION', 'RECIPIENT_COUNTRY',\n",
    "    'RECIPIENT_COUNTRY_CODE','RECIPIENT_NGDS_THEATER','RECIPIENT_NGDS_REGION'    \n",
    "]\n",
    "data = data.drop(columns = cols_to_drop)\n",
    "\n",
    "#Removing N/A Service types\n",
    "data['SERVICE_LVL_CD_DESC'] = data['SERVICE_LVL_CD_DESC'].replace({\n",
    "    'Home Delivery':'FedEx Home Delivery',\n",
    "    'Ground':'FedEx Ground'})\n",
    "\n",
    "#Filtering for only the lower 48 States & DC\n",
    "state_abbreviations = ['AL', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'ID',\n",
    "                       'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI',\n",
    "                       'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY',\n",
    "                       'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN',\n",
    "                       'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'DC']\n",
    "data = data[data['RECIPIENT_STATE_PRVNC'].isin(state_abbreviations)]\n",
    "data = data[data['SHIPPER_STATE_PRVNC'].isin(state_abbreviations)]\n",
    "\n",
    "#Converting Pick-up time to Date-time object\n",
    "data['ACTUAL_PICKUP_DATE'] = pd.to_datetime(data['ACTUAL_PICKUP_DATE'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a06cdd-0c8a-406f-8481-96c2714773e3",
   "metadata": {},
   "source": [
    "# Zone Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686968f-9f09-4771-b113-4e08a0e91d20",
   "metadata": {},
   "source": [
    "## Zone Assignments - City Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c747e-e23f-4e36-9689-7e3c20eaf7b3",
   "metadata": {},
   "source": [
    "Using data from the US Census Bureau, we will match City/State names with coordinates, using those to calculate shipping distance and then shipping zone. \n",
    "\n",
    "Then using another dataset, we will match Shipper/Recipient Zip codes for each package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7b9a5-1929-4027-90e2-f8f0e014483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and clean places DF\n",
    "places = pd.read_csv(\"PopulatedPlaces_National.txt\", delimiter = \"|\")\n",
    "\n",
    "#Only Columns needed: City, State, Lat, Long\n",
    "places = places[['feature_name','state_name','prim_lat_dec','prim_long_dec']]\n",
    "\n",
    "#Rename Columns\n",
    "rn = {'feature_name':'city','state_name':'state','prim_lat_dec':'lat','prim_long_dec':'long'}\n",
    "places = places.rename(columns = rn)\n",
    "\n",
    "#Creating State Abbreviations\n",
    "places['state'] = places['state'].replace({\n",
    "    \"Alabama\": \"AL\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\",\"Delaware\": \"DE\", \"District of Columbia\": \"DC\",\n",
    "    \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\", \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\", \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\", \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "})\n",
    "\n",
    "#City to UPPER\n",
    "places['city'] = places['city'].map(lambda x: x.upper())\n",
    "\n",
    "#Replace Values in Places\n",
    "replace = {\n",
    "    'SAINT LOUIS':'ST. LOUIS',\n",
    "    'SAINT PETERSBURG':'ST. PETERSBURG',\n",
    "    'CHICAGO LOOP':'CHICAGO',\n",
    "    'LAKE WORTH BEACH':'LAKE WORTH',\n",
    "    'PARKCHESTER': 'THE BRONX',\n",
    "    'LEES SUMMIT':\"LEE'S SUMMIT\", \n",
    "}\n",
    "places['city'] = places['city'].replace(replace)\n",
    "\n",
    "#Lower 48 & DC Only\n",
    "places = places[places['state'].isin(state_abbreviations)]\n",
    "\n",
    "#Merging Places with TRANSCOM data to get Lats and Longs \n",
    "data = data.merge(places, how='left',\n",
    "                  left_on = ['RECIPIENT_CITY_NAME', 'RECIPIENT_STATE_PRVNC'],\n",
    "                  right_on = ['city', 'state']).merge(places, \n",
    "                                                      how = 'left',\n",
    "                                                      left_on = ['SHIPPER_CITY_NAME', 'SHIPPER_STATE_PRVNC'],\n",
    "                                                      right_on = ['city', 'state'],\n",
    "                                                      suffixes = ['_RECIPIENT','_SHIPPER']).drop(columns=['city_RECIPIENT','city_SHIPPER','state_RECIPIENT','state_SHIPPER'])\n",
    "\n",
    "#Calculating distances betweem Shipper City & Recipient City\n",
    "def calculate_distance(df, lat1, lon1, lat2, lon2):\n",
    "    coords_1 = list(zip(df[lat1], df[lon1]))\n",
    "    coords_2 = list(zip(df[lat2], df[lon2]))\n",
    "    distances = [haversine(coord1, coord2, unit=Unit.MILES) for coord1, coord2 in zip(coords_1, coords_2)]\n",
    "    return pd.Series(distances)\n",
    "    \n",
    "data['miles'] = calculate_distance(data, 'lat_RECIPIENT', 'long_RECIPIENT', 'lat_SHIPPER', 'long_SHIPPER')\n",
    "data = data.drop(columns = ['lat_RECIPIENT', 'long_RECIPIENT', 'lat_SHIPPER', 'long_SHIPPER'])\n",
    "\n",
    "#Creating Zones based on calculated distances\n",
    "bins = [-1, 50, 150, 300, 600, 1000, 1400, 1800, float('inf')]\n",
    "labels = ['Zone 1', 'Zone 2', 'Zone 3', 'Zone 4', 'Zone 5', 'Zone 6', 'Zone 7', 'Zone 8']\n",
    "data['ZONE'] = pd.cut(data['miles'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "#Clean up\n",
    "del places\n",
    "data = data.drop(columns='miles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c23b19-f0ee-4859-a2c8-2e62225ebb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZIP CODE MAPPINGS\n",
    "\n",
    "#Import USZIPS dataset\n",
    "usa = pd.read_csv(\"uszips.csv\")\n",
    "usa = usa[['zip','city','state_id']]\n",
    "usa = usa.drop_duplicates(subset = ['city','state_id'])\n",
    "usa['city'] = usa['city'].str.upper()\n",
    "\n",
    "#Map ZIPs to dataset\n",
    "data = pd.merge(data, usa, \n",
    "                  left_on=['SHIPPER_CITY_NAME','SHIPPER_STATE_PRVNC'],\n",
    "                 right_on = ['city','state_id'], how = 'left')\n",
    "data = data.drop(['city','state_id'], axis = 1)\n",
    "data = data.rename(columns = {'zip':'SHIPPER_ZIP'})\n",
    "\n",
    "data = pd.merge(data, usa, \n",
    "                  left_on=['RECIPIENT_CITY_NAME','RECIPIENT_STATE_PRVNC'],\n",
    "                 right_on = ['city','state_id'], how = 'left')\n",
    "data = data.drop(['city','state_id'], axis = 1)\n",
    "data = data.rename(columns = {'zip':'RECIPIENT_ZIP'})\n",
    "\n",
    "del usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ec6de-425b-457a-be29-17643a9a6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in some large missing values\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'ST. LOUIS') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '63101'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'ST. LOUIS') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '63101'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'URBANCREST') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '43123'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'URBANCREST') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '43123'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'ST. PETERSBURG') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '33701'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'ST. PETERSBURG') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '33701'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'THE BRONX') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '10460'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'THE BRONX') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '10460'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'RIVIERA BEACH') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '33404'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'RIVIERA BEACH') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '33404'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'LANDOVER') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '20784'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'LANDOVER') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '20784'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'SOUTHAVEN') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '63101'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'SOUTHAVEN') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '63101'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'WILKES-BARRE') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '18701'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'WILKES-BARRE') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '18701'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'MOUNTAIN HOME') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '37684'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'MOUNTAIN HOME') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '37684'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'COMMERCE') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '90022'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'COMMERCE') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '90022'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'CITY OF INDUSTRY') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '90601'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'CITY OF INDUSTRY') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '90601'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'IRWINDALE') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '91006'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'IRWINDALE') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '91006'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'VERNON') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '90023'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'VERNON') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '90023'\n",
    "\n",
    "data.loc[(data['SHIPPER_CITY_NAME'] == 'EASTVALE') & (data['SHIPPER_ZIP'].isna()), 'SHIPPER_ZIP'] = '91752'\n",
    "data.loc[(data['RECIPIENT_CITY_NAME'] == 'EASTVALE') & (data['RECIPIENT_ZIP'].isna()), 'RECIPIENT_ZIP'] = '91752'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b2436-cc8b-46ce-b1c3-6ecc9953cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate USPS and Fedex\n",
    "service_levels = ['UPS Ground', 'UPS Next Day Air', 'UPS 2nd Day Air', 'UPS Next Day Air Saver',\n",
    "                  'UPS 3 Day Select', 'UPS Next Day Air Early A.M. / UPS Next Day Air Early', 'UPS 2nd Day Air A.M.',\n",
    "                  'FedEx Home Delivery', 'FedEx Priority Overnight', 'FedEx Standard Overnight', 'FedEx Ground',\n",
    "                  'FedEx Economy', 'FedEx 2Day', 'FedEx First Overnight', 'FedEx 2Day AM', 'FedEx Express Saver']\n",
    "\n",
    "data_zoned = data[(data['ZONE'].notnull()) | (~data['SERVICE_LVL_CD_DESC'].isin(service_levels))].copy()\n",
    "data = data[data['ZONE'].isnull() & (data['SERVICE_LVL_CD_DESC'].isin(service_levels))].drop(columns = [\"ZONE\"])\n",
    "upso = data[data['CARRIER_SCAC'] == 'UPSO'].copy()\n",
    "fedx = data[data['CARRIER_SCAC'] == 'FEDX'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff646f-1fb9-44d2-9bd6-4d7f8fa7f100",
   "metadata": {},
   "source": [
    "## Zone Assignments - UPS Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465807a-1f7d-4b6d-9e15-3af0cda1a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPS Ground\n",
    "upso_ground = upso[upso['SERVICE_LVL_CD_DESC'] == 'UPS Ground'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "upso_ground_fy23 = upso_ground[upso_ground['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "upso_ground_fy24 = upso_ground[(upso_ground['ACTUAL_PICKUP_DATE'] >= date_before) & (upso_ground['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "upso_ground_fy25 = upso_ground[upso_ground['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "upso_ground_rates_fy23 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ground_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ground_rates_fy24 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ground_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ground_rates_fy25_ = pd.read_excel('upso_costs.xlsx', sheet_name = 'ground_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ground_rates_fy25a = pd.read_excel('upso_costs.xlsx', sheet_name = 'ground_rates_fy25a').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ground_rates_fy25 = pd.concat([upso_ground_rates_fy25_,upso_ground_rates_fy25a], ignore_index = True)\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "upso_ground_zoned_fy23 = pd.merge(upso_ground_fy23, upso_ground_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ground_zoned_fy24 = pd.merge(upso_ground_fy24, upso_ground_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ground_zoned_fy25 = pd.merge(upso_ground_fy25, upso_ground_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_ground_zoned_fy = pd.concat([upso_ground_zoned_fy23, upso_ground_zoned_fy24, upso_ground_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "upso_ground_zoned0 = upso_ground_zoned_fy[upso_ground_zoned_fy['ZONE'].notnull()].copy()\n",
    "upso_ground_missing1 = upso_ground_zoned_fy[upso_ground_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "upso_ground_retry1 = upso_ground_missing1.merge(upso_ground_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ground_zoned1 = upso_ground_retry1[upso_ground_retry1['ZONE'].notnull()].copy()\n",
    "upso_ground_missing2 = upso_ground_retry1[upso_ground_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_ground_retry2 = upso_ground_missing2.merge(upso_ground_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ground_zoned2 = upso_ground_retry2[upso_ground_retry2['ZONE'].notnull()].copy()\n",
    "upso_ground_missing3 = upso_ground_retry2[upso_ground_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_ground_retry3 = upso_ground_missing3.merge(upso_ground_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_ground_zoned = pd.concat([upso_ground_zoned0, upso_ground_zoned1, upso_ground_zoned2, upso_ground_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del upso_ground, upso_ground_fy23, upso_ground_fy24, upso_ground_fy25, upso_ground_rates_fy23, upso_ground_rates_fy24, upso_ground_rates_fy25\n",
    "del upso_ground_zoned_fy23, upso_ground_zoned_fy24, upso_ground_zoned_fy25, upso_ground_zoned_fy, upso_ground_zoned0, upso_ground_zoned1\n",
    "del upso_ground_zoned2, upso_ground_retry1, upso_ground_retry2, upso_ground_retry3, upso_ground_missing1, upso_ground_missing2, upso_ground_missing3\n",
    "\n",
    "print(f'UPS Ground Merge Results')\n",
    "print(f'Missing Zones: ',upso_ground_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_ground_zoned))\n",
    "print(round(((upso_ground_zoned[\"ZONE\"].isna().sum() / len(upso_ground_zoned))*100),2), f'% Zones Missing')\n",
    "\n",
    "\n",
    "#Shipper 80401 to Recipient 89101 (appears 507 times) is showing for Zone 5, but should be in Zone 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5c2cc-4e16-4b3c-80ff-802a564d8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPS Next Day Air\n",
    "upso_nda = upso[upso['SERVICE_LVL_CD_DESC'] == 'UPS Next Day Air'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "upso_nda_fy23 = upso_nda[upso_nda['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "upso_nda_fy24 = upso_nda[(upso_nda['ACTUAL_PICKUP_DATE'] >= date_before) & (upso_nda['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "upso_nda_fy25 = upso_nda[upso_nda['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "upso_nda_rates_fy23 = pd.read_excel('upso_costs.xlsx', sheet_name = 'nda_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_nda_rates_fy24 = pd.read_excel('upso_costs.xlsx', sheet_name = 'nda_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_nda_rates_fy25 = pd.read_excel('upso_costs.xlsx', sheet_name = 'nda_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "upso_nda_zoned_fy23 = pd.merge(upso_nda_fy23, upso_nda_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_nda_zoned_fy24 = pd.merge(upso_nda_fy24, upso_nda_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_nda_zoned_fy25 = pd.merge(upso_nda_fy25, upso_nda_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_nda_zoned_fy = pd.concat([upso_nda_zoned_fy23, upso_nda_zoned_fy24, upso_nda_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "upso_nda_zoned0 = upso_nda_zoned_fy[upso_nda_zoned_fy['ZONE'].notnull()].copy()\n",
    "upso_nda_missing1 = upso_nda_zoned_fy[upso_nda_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "upso_nda_retry1 = upso_nda_missing1.merge(upso_nda_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_nda_zoned1 = upso_nda_retry1[upso_nda_retry1['ZONE'].notnull()].copy()\n",
    "upso_nda_missing2 = upso_nda_retry1[upso_nda_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_nda_retry2 = upso_nda_missing2.merge(upso_nda_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_nda_zoned2 = upso_nda_retry2[upso_nda_retry2['ZONE'].notnull()].copy()\n",
    "upso_nda_missing3 = upso_nda_retry2[upso_nda_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_nda_retry3 = upso_nda_missing3.merge(upso_nda_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_nda_zoned = pd.concat([upso_nda_zoned0, upso_nda_zoned1, upso_nda_zoned2, upso_nda_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del upso_nda, upso_nda_fy23, upso_nda_fy24, upso_nda_fy25, upso_nda_rates_fy23, upso_nda_rates_fy24, upso_nda_rates_fy25\n",
    "del upso_nda_zoned_fy23, upso_nda_zoned_fy24, upso_nda_zoned_fy25, upso_nda_zoned_fy, upso_nda_zoned0, upso_nda_zoned1\n",
    "del upso_nda_zoned2, upso_nda_retry1, upso_nda_retry2, upso_nda_retry3, upso_nda_missing1, upso_nda_missing2, upso_nda_missing3\n",
    "\n",
    "print(f'UPS Next Day Air Merge Results')\n",
    "print(f'Missing Zones: ',upso_nda_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_nda_zoned))\n",
    "print(round(((upso_nda_zoned[\"ZONE\"].isna().sum() / len(upso_nda_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df8d7a-d528-42c3-b8c7-09abbb6efbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPS 2nd Day Air\n",
    "upso_2da = upso[upso['SERVICE_LVL_CD_DESC'] == 'UPS 2nd Day Air'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "upso_2da_fy23 = upso_2da[upso_2da['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "upso_2da_fy24 = upso_2da[(upso_2da['ACTUAL_PICKUP_DATE'] >= date_before) & (upso_2da['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "upso_2da_fy25 = upso_2da[upso_2da['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "upso_2da_rates_fy23 = pd.read_excel('upso_costs.xlsx', sheet_name = '2da_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_2da_rates_fy24 = pd.read_excel('upso_costs.xlsx', sheet_name = '2da_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_2da_rates_fy25 = pd.read_excel('upso_costs.xlsx', sheet_name = '2da_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "upso_2da_zoned_fy23 = pd.merge(upso_2da_fy23, upso_2da_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2da_zoned_fy24 = pd.merge(upso_2da_fy24, upso_2da_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2da_zoned_fy25 = pd.merge(upso_2da_fy25, upso_2da_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_2da_zoned_fy = pd.concat([upso_2da_zoned_fy23, upso_2da_zoned_fy24, upso_2da_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "upso_2da_zoned0 = upso_2da_zoned_fy[upso_2da_zoned_fy['ZONE'].notnull()].copy()\n",
    "upso_2da_missing1 = upso_2da_zoned_fy[upso_2da_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "upso_2da_retry1 = upso_2da_missing1.merge(upso_2da_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2da_zoned1 = upso_2da_retry1[upso_2da_retry1['ZONE'].notnull()].copy()\n",
    "upso_2da_missing2 = upso_2da_retry1[upso_2da_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_2da_retry2 = upso_2da_missing2.merge(upso_2da_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2da_zoned2 = upso_2da_retry2[upso_2da_retry2['ZONE'].notnull()].copy()\n",
    "upso_2da_missing3 = upso_2da_retry2[upso_2da_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_2da_retry3 = upso_2da_missing3.merge(upso_2da_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_2da_zoned = pd.concat([upso_2da_zoned0, upso_2da_zoned1, upso_2da_zoned2, upso_2da_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del upso_2da, upso_2da_fy23, upso_2da_fy24, upso_2da_fy25, upso_2da_rates_fy23, upso_2da_rates_fy24, upso_2da_rates_fy25\n",
    "del upso_2da_zoned_fy23, upso_2da_zoned_fy24, upso_2da_zoned_fy25, upso_2da_zoned_fy, upso_2da_zoned0, upso_2da_zoned1\n",
    "del upso_2da_zoned2, upso_2da_retry1, upso_2da_retry2, upso_2da_retry3, upso_2da_missing1, upso_2da_missing2, upso_2da_missing3\n",
    "\n",
    "print(f'UPS 2nd Day Air Merge Results')\n",
    "print(f'Missing Zones: ',upso_2da_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_2da_zoned))\n",
    "print(round(((upso_2da_zoned[\"ZONE\"].isna().sum() / len(upso_2da_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e31f4-6a18-44e8-86cd-e3b96aeba12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPS Next Day Air Saver\n",
    "upso_ndas = upso[upso['SERVICE_LVL_CD_DESC'] == 'UPS Next Day Air Saver'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "upso_ndas_fy23 = upso_ndas[upso_ndas['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "upso_ndas_fy24 = upso_ndas[(upso_ndas['ACTUAL_PICKUP_DATE'] >= date_before) & (upso_ndas['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "upso_ndas_fy25 = upso_ndas[upso_ndas['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "upso_ndas_rates_fy23 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ndas_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ndas_rates_fy24 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ndas_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ndas_rates_fy25 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ndas_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "upso_ndas_zoned_fy23 = pd.merge(upso_ndas_fy23, upso_ndas_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndas_zoned_fy24 = pd.merge(upso_ndas_fy24, upso_ndas_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndas_zoned_fy25 = pd.merge(upso_ndas_fy25, upso_ndas_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_ndas_zoned_fy = pd.concat([upso_ndas_zoned_fy23, upso_ndas_zoned_fy24, upso_ndas_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "upso_ndas_zoned0 = upso_ndas_zoned_fy[upso_ndas_zoned_fy['ZONE'].notnull()].copy()\n",
    "upso_ndas_missing1 = upso_ndas_zoned_fy[upso_ndas_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "upso_ndas_retry1 = upso_ndas_missing1.merge(upso_ndas_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndas_zoned1 = upso_ndas_retry1[upso_ndas_retry1['ZONE'].notnull()].copy()\n",
    "upso_ndas_missing2 = upso_ndas_retry1[upso_ndas_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_ndas_retry2 = upso_ndas_missing2.merge(upso_ndas_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndas_zoned2 = upso_ndas_retry2[upso_ndas_retry2['ZONE'].notnull()].copy()\n",
    "upso_ndas_missing3 = upso_ndas_retry2[upso_ndas_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_ndas_retry3 = upso_ndas_missing3.merge(upso_ndas_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_ndas_zoned = pd.concat([upso_ndas_zoned0, upso_ndas_zoned1, upso_ndas_zoned2, upso_ndas_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del upso_ndas, upso_ndas_fy23, upso_ndas_fy24, upso_ndas_fy25, upso_ndas_rates_fy23, upso_ndas_rates_fy24, upso_ndas_rates_fy25\n",
    "del upso_ndas_zoned_fy23, upso_ndas_zoned_fy24, upso_ndas_zoned_fy25, upso_ndas_zoned_fy, upso_ndas_zoned0, upso_ndas_zoned1\n",
    "del upso_ndas_zoned2, upso_ndas_retry1, upso_ndas_retry2, upso_ndas_retry3, upso_ndas_missing1, upso_ndas_missing2, upso_ndas_missing3\n",
    "\n",
    "print(f'UPS Next Day Air Saver Merge Results')\n",
    "print(f'Missing Zones: ',upso_ndas_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_ndas_zoned))\n",
    "print(round(((upso_ndas_zoned[\"ZONE\"].isna().sum() / len(upso_ndas_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb22ca-aa53-4c11-89ef-f646e2fa6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPS 3 Day Select\n",
    "upso_3ds = upso[upso['SERVICE_LVL_CD_DESC'] == 'UPS 3 Day Select'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "upso_3ds_fy23 = upso_3ds[upso_3ds['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "upso_3ds_fy24 = upso_3ds[(upso_3ds['ACTUAL_PICKUP_DATE'] >= date_before) & (upso_3ds['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "upso_3ds_fy25 = upso_3ds[upso_3ds['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "upso_3ds_rates_fy23 = pd.read_excel('upso_costs.xlsx', sheet_name = '3ds_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_3ds_rates_fy24 = pd.read_excel('upso_costs.xlsx', sheet_name = '3ds_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_3ds_rates_fy25 = pd.read_excel('upso_costs.xlsx', sheet_name = '3ds_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "upso_3ds_zoned_fy23 = pd.merge(upso_3ds_fy23, upso_3ds_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_3ds_zoned_fy24 = pd.merge(upso_3ds_fy24, upso_3ds_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_3ds_zoned_fy25 = pd.merge(upso_3ds_fy25, upso_3ds_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_3ds_zoned_fy = pd.concat([upso_3ds_zoned_fy23, upso_3ds_zoned_fy24, upso_3ds_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "upso_3ds_zoned0 = upso_3ds_zoned_fy[upso_3ds_zoned_fy['ZONE'].notnull()].copy()\n",
    "upso_3ds_missing1 = upso_3ds_zoned_fy[upso_3ds_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "upso_3ds_retry1 = upso_3ds_missing1.merge(upso_3ds_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_3ds_zoned1 = upso_3ds_retry1[upso_3ds_retry1['ZONE'].notnull()].copy()\n",
    "upso_3ds_missing2 = upso_3ds_retry1[upso_3ds_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_3ds_retry2 = upso_3ds_missing2.merge(upso_3ds_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_3ds_zoned2 = upso_3ds_retry2[upso_3ds_retry2['ZONE'].notnull()].copy()\n",
    "upso_3ds_missing3 = upso_3ds_retry2[upso_3ds_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_3ds_retry3 = upso_3ds_missing3.merge(upso_3ds_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_3ds_zoned = pd.concat([upso_3ds_zoned0, upso_3ds_zoned1, upso_3ds_zoned2, upso_3ds_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del upso_3ds, upso_3ds_fy23, upso_3ds_fy24, upso_3ds_fy25, upso_3ds_rates_fy23, upso_3ds_rates_fy24, upso_3ds_rates_fy25\n",
    "del upso_3ds_zoned_fy23, upso_3ds_zoned_fy24, upso_3ds_zoned_fy25, upso_3ds_zoned_fy, upso_3ds_zoned0, upso_3ds_zoned1\n",
    "del upso_3ds_zoned2, upso_3ds_retry1, upso_3ds_retry2, upso_3ds_retry3, upso_3ds_missing1, upso_3ds_missing2, upso_3ds_missing3\n",
    "\n",
    "print(f'UPS 3 Day Select Merge Results')\n",
    "print(f'Missing Zones: ',upso_3ds_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_3ds_zoned))\n",
    "print(round(((upso_3ds_zoned[\"ZONE\"].isna().sum() / len(upso_3ds_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83361461-d8fc-4ed7-af96-ea44c3000229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPS Next Day Air Early A.M. / UPS Next Day Air Early\n",
    "upso_ndae = upso[upso['SERVICE_LVL_CD_DESC'] == 'UPS Next Day Air Early A.M. / UPS Next Day Air Early'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "upso_ndae_fy23 = upso_ndae[upso_ndae['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "upso_ndae_fy24 = upso_ndae[(upso_ndae['ACTUAL_PICKUP_DATE'] >= date_before) & (upso_ndae['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "upso_ndae_fy25 = upso_ndae[upso_ndae['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "upso_ndae_rates_fy23 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ndae_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ndae_rates_fy24 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ndae_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_ndae_rates_fy25 = pd.read_excel('upso_costs.xlsx', sheet_name = 'ndae_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "upso_ndae_zoned_fy23 = pd.merge(upso_ndae_fy23, upso_ndae_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndae_zoned_fy24 = pd.merge(upso_ndae_fy24, upso_ndae_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndae_zoned_fy25 = pd.merge(upso_ndae_fy25, upso_ndae_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_ndae_zoned_fy = pd.concat([upso_ndae_zoned_fy23, upso_ndae_zoned_fy24, upso_ndae_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "upso_ndae_zoned0 = upso_ndae_zoned_fy[upso_ndae_zoned_fy['ZONE'].notnull()].copy()\n",
    "upso_ndae_missing1 = upso_ndae_zoned_fy[upso_ndae_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "upso_ndae_retry1 = upso_ndae_missing1.merge(upso_ndae_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndae_zoned1 = upso_ndae_retry1[upso_ndae_retry1['ZONE'].notnull()].copy()\n",
    "upso_ndae_missing2 = upso_ndae_retry1[upso_ndae_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_ndae_retry2 = upso_ndae_missing2.merge(upso_ndae_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_ndae_zoned2 = upso_ndae_retry2[upso_ndae_retry2['ZONE'].notnull()].copy()\n",
    "upso_ndae_missing3 = upso_ndae_retry2[upso_ndae_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_ndae_retry3 = upso_ndae_missing3.merge(upso_ndae_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_ndae_zoned = pd.concat([upso_ndae_zoned0, upso_ndae_zoned1, upso_ndae_zoned2, upso_ndae_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del upso_ndae, upso_ndae_fy23, upso_ndae_fy24, upso_ndae_fy25, upso_ndae_rates_fy23, upso_ndae_rates_fy24, upso_ndae_rates_fy25\n",
    "del upso_ndae_zoned_fy23, upso_ndae_zoned_fy24, upso_ndae_zoned_fy25, upso_ndae_zoned_fy, upso_ndae_zoned0, upso_ndae_zoned1\n",
    "del upso_ndae_zoned2, upso_ndae_retry1, upso_ndae_retry2, upso_ndae_retry3, upso_ndae_missing1, upso_ndae_missing2, upso_ndae_missing3\n",
    "\n",
    "print(f'UPS Next Day Air Early A.M. / UPS Next Day Air Early Merge Results')\n",
    "print(f'Missing Zones: ',upso_ndae_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_ndae_zoned))\n",
    "print(round(((upso_ndae_zoned[\"ZONE\"].isna().sum() / len(upso_ndae_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5967d-aa11-4702-a55e-84c1497ac43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPS 2nd Day Air A.M.\n",
    "upso_2daam = upso[upso['SERVICE_LVL_CD_DESC'] == 'UPS 2nd Day Air A.M.'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "upso_2daam_fy23 = upso_2daam[upso_2daam['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "upso_2daam_fy24 = upso_2daam[(upso_2daam['ACTUAL_PICKUP_DATE'] >= date_before) & (upso_2daam['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "upso_2daam_fy25 = upso_2daam[upso_2daam['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "upso_2daam_rates_fy23 = pd.read_excel('upso_costs.xlsx', sheet_name = '2daam_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_2daam_rates_fy24 = pd.read_excel('upso_costs.xlsx', sheet_name = '2daam_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "upso_2daam_rates_fy25 = pd.read_excel('upso_costs.xlsx', sheet_name = '2daam_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "upso_2daam_zoned_fy23 = pd.merge(upso_2daam_fy23, upso_2daam_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2daam_zoned_fy24 = pd.merge(upso_2daam_fy24, upso_2daam_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2daam_zoned_fy25 = pd.merge(upso_2daam_fy25, upso_2daam_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_2daam_zoned_fy = pd.concat([upso_2daam_zoned_fy23, upso_2daam_zoned_fy24, upso_2daam_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "upso_2daam_zoned0 = upso_2daam_zoned_fy[upso_2daam_zoned_fy['ZONE'].notnull()].copy()\n",
    "upso_2daam_missing1 = upso_2daam_zoned_fy[upso_2daam_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "upso_2daam_retry1 = upso_2daam_missing1.merge(upso_2daam_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2daam_zoned1 = upso_2daam_retry1[upso_2daam_retry1['ZONE'].notnull()].copy()\n",
    "upso_2daam_missing2 = upso_2daam_retry1[upso_2daam_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_2daam_retry2 = upso_2daam_missing2.merge(upso_2daam_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "upso_2daam_zoned2 = upso_2daam_retry2[upso_2daam_retry2['ZONE'].notnull()].copy()\n",
    "upso_2daam_missing3 = upso_2daam_retry2[upso_2daam_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "upso_2daam_retry3 = upso_2daam_missing3.merge(upso_2daam_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "upso_2daam_zoned = pd.concat([upso_2daam_zoned0, upso_2daam_zoned1, upso_2daam_zoned2, upso_2daam_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del upso_2daam, upso_2daam_fy23, upso_2daam_fy24, upso_2daam_fy25, upso_2daam_rates_fy23, upso_2daam_rates_fy24, upso_2daam_rates_fy25\n",
    "del upso_2daam_zoned_fy23, upso_2daam_zoned_fy24, upso_2daam_zoned_fy25, upso_2daam_zoned_fy, upso_2daam_zoned0, upso_2daam_zoned1\n",
    "del upso_2daam_zoned2, upso_2daam_retry1, upso_2daam_retry2, upso_2daam_retry3, upso_2daam_missing1, upso_2daam_missing2, upso_2daam_missing3\n",
    "\n",
    "print(f'UPS 2nd Day Air A.M. Merge Results')\n",
    "print(f'Missing Zones: ',upso_2daam_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_2daam_zoned))\n",
    "print(round(((upso_2daam_zoned[\"ZONE\"].isna().sum() / len(upso_2daam_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bef003-3e2f-45a7-9b4e-58a6026acfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append all UPS\n",
    "upso_dfs = [upso_ground_zoned, upso_nda_zoned, upso_2da_zoned, upso_ndas_zoned, upso_3ds_zoned, upso_ndae_zoned, upso_2daam_zoned]\n",
    "upso_zoned = pd.concat(upso_dfs, ignore_index = True)\n",
    "\n",
    "del upso_ground_zoned, upso_nda_zoned, upso_2da_zoned, upso_ndas_zoned, upso_3ds_zoned, upso_ndae_zoned, upso_2daam_zoned\n",
    "\n",
    "print(f'UPS Merge Results')\n",
    "print(f'Missing Zones: ',upso_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(upso_zoned))\n",
    "print(round(((upso_zoned[\"ZONE\"].isna().sum() / len(upso_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d3e5b-b83e-486f-b275-7ddceeb2ad9c",
   "metadata": {},
   "source": [
    "## Zone Assignments - FEDEX Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851c71a-7253-4970-bf4e-a2990d4e1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDEX Home Delivery\n",
    "fedx_hd = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx Home Delivery'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_hd_fy23 = fedx_hd[fedx_hd['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "fedx_hd_fy24 = fedx_hd[(fedx_hd['ACTUAL_PICKUP_DATE'] >= date_before) & (fedx_hd['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_hd_fy25 = fedx_hd[fedx_hd['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_hd_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'hd_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_hd_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'hd_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_hd_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'hd_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_hd_zoned_fy23 = pd.merge(fedx_hd_fy23, fedx_hd_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_hd_zoned_fy24 = pd.merge(fedx_hd_fy24, fedx_hd_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_hd_zoned_fy25 = pd.merge(fedx_hd_fy25, fedx_hd_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_hd_zoned_fy = pd.concat([fedx_hd_zoned_fy23, fedx_hd_zoned_fy24, fedx_hd_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_hd_zoned0 = fedx_hd_zoned_fy[fedx_hd_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_hd_missing1 = fedx_hd_zoned_fy[fedx_hd_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_hd_retry1 = fedx_hd_missing1.merge(fedx_hd_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_hd_zoned1 = fedx_hd_retry1[fedx_hd_retry1['ZONE'].notnull()].copy()\n",
    "fedx_hd_missing2 = fedx_hd_retry1[fedx_hd_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_hd_retry2 = fedx_hd_missing2.merge(fedx_hd_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_hd_zoned2 = fedx_hd_retry2[fedx_hd_retry2['ZONE'].notnull()].copy()\n",
    "fedx_hd_missing3 = fedx_hd_retry2[fedx_hd_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_hd_retry3 = fedx_hd_missing3.merge(fedx_hd_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_hd_zoned = pd.concat([fedx_hd_zoned0, fedx_hd_zoned1, fedx_hd_zoned2, fedx_hd_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_hd, fedx_hd_fy23, fedx_hd_fy24, fedx_hd_fy25, fedx_hd_rates_fy23, fedx_hd_rates_fy24, fedx_hd_rates_fy25\n",
    "del fedx_hd_zoned_fy23, fedx_hd_zoned_fy24, fedx_hd_zoned_fy25, fedx_hd_zoned_fy, fedx_hd_zoned0, fedx_hd_zoned1\n",
    "del fedx_hd_zoned2, fedx_hd_retry1, fedx_hd_retry2, fedx_hd_retry3, fedx_hd_missing1, fedx_hd_missing2, fedx_hd_missing3\n",
    "\n",
    "print(f'FEDEX Home Delivery Merge Results')\n",
    "print(f'Missing Zones: ',fedx_hd_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_hd_zoned))\n",
    "print(round(((fedx_hd_zoned[\"ZONE\"].isna().sum() / len(fedx_hd_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd766d-ec0c-4112-ac2a-ee531615f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDEX Priority Overnight\n",
    "fedx_po = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx Priority Overnight'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_po_fy23 = fedx_po[fedx_po['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "fedx_po_fy24 = fedx_po[(fedx_po['ACTUAL_PICKUP_DATE'] >= date_before) & (fedx_po['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_po_fy25 = fedx_po[fedx_po['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_po_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'po_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_po_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'po_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_po_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'po_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "fedx_po['BILLED_WEIGHT'] = fedx_po['BILLED_WEIGHT'].astype('float')\n",
    "fedx_po['TOTAL_FREIGHT_AMOUNT'] = fedx_po['TOTAL_FREIGHT_AMOUNT'].astype('float')\n",
    "fedx_po_rates_fy23['FreightPrice'] = fedx_po_rates_fy23['FreightPrice'].astype('float')\n",
    "fedx_po_rates_fy23['WEIGHT'] = fedx_po_rates_fy23['WEIGHT'].astype('float32')\n",
    "fedx_po_rates_fy24['FreightPrice'] = fedx_po_rates_fy24['FreightPrice'].astype('float')\n",
    "fedx_po_rates_fy24['WEIGHT'] = fedx_po_rates_fy24['WEIGHT'].astype('float')\n",
    "fedx_po_rates_fy25['FreightPrice'] = fedx_po_rates_fy25['FreightPrice'].astype('float')\n",
    "fedx_po_rates_fy25['WEIGHT'] = fedx_po_rates_fy25['WEIGHT'].astype('float')\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_po_zoned_fy23 = pd.merge(fedx_po_fy23, fedx_po_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_po_zoned_fy24 = pd.merge(fedx_po_fy24, fedx_po_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_po_zoned_fy25 = pd.merge(fedx_po_fy25, fedx_po_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_po_zoned_fy = pd.concat([fedx_po_zoned_fy23, fedx_po_zoned_fy24, fedx_po_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_po_zoned0 = fedx_po_zoned_fy[fedx_po_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_po_missing1 = fedx_po_zoned_fy[fedx_po_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_po_retry1 = fedx_po_missing1.merge(fedx_po_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_po_zoned1 = fedx_po_retry1[fedx_po_retry1['ZONE'].notnull()].copy()\n",
    "fedx_po_missing2 = fedx_po_retry1[fedx_po_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_po_retry2 = fedx_po_missing2.merge(fedx_po_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_po_zoned2 = fedx_po_retry2[fedx_po_retry2['ZONE'].notnull()].copy()\n",
    "fedx_po_missing3 = fedx_po_retry2[fedx_po_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_po_retry3 = fedx_po_missing3.merge(fedx_po_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_po_zoned = pd.concat([fedx_po_zoned0, fedx_po_zoned1, fedx_po_zoned2, fedx_po_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_po, fedx_po_fy23, fedx_po_fy24, fedx_po_fy25, fedx_po_rates_fy23, fedx_po_rates_fy24, fedx_po_rates_fy25\n",
    "del fedx_po_zoned_fy23, fedx_po_zoned_fy24, fedx_po_zoned_fy25, fedx_po_zoned_fy, fedx_po_zoned0, fedx_po_zoned1\n",
    "del fedx_po_zoned2, fedx_po_retry1, fedx_po_retry2, fedx_po_retry3, fedx_po_missing1, fedx_po_missing2, fedx_po_missing3\n",
    "\n",
    "print(f'FEDEX Priority Overnight Merge Results')\n",
    "print(f'Missing Zones: ',fedx_po_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_po_zoned))\n",
    "print(round(((fedx_po_zoned[\"ZONE\"].isna().sum() / len(fedx_po_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f2a14-ad0c-4f38-9193-8016e068d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDEX Standard Overnight\n",
    "fedx_so = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx Standard Overnight'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_so_fy23 = fedx_so[fedx_so['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "fedx_so_fy24 = fedx_so[(fedx_so['ACTUAL_PICKUP_DATE'] >= date_before) & (fedx_so['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_so_fy25 = fedx_so[fedx_so['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_so_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'so_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_so_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'so_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_so_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'so_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "fedx_so['BILLED_WEIGHT'] = fedx_so['BILLED_WEIGHT'].astype('float')\n",
    "fedx_so['TOTAL_FREIGHT_AMOUNT'] = fedx_so['TOTAL_FREIGHT_AMOUNT'].astype('float')\n",
    "fedx_so_rates_fy23['FreightPrice'] = fedx_so_rates_fy23['FreightPrice'].astype('float')\n",
    "fedx_so_rates_fy23['WEIGHT'] = fedx_so_rates_fy23['WEIGHT'].astype('float32')\n",
    "fedx_so_rates_fy24['FreightPrice'] = fedx_so_rates_fy24['FreightPrice'].astype('float')\n",
    "fedx_so_rates_fy24['WEIGHT'] = fedx_so_rates_fy24['WEIGHT'].astype('float')\n",
    "fedx_so_rates_fy25['FreightPrice'] = fedx_so_rates_fy25['FreightPrice'].astype('float')\n",
    "fedx_so_rates_fy25['WEIGHT'] = fedx_so_rates_fy25['WEIGHT'].astype('float')\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_so_zoned_fy23 = pd.merge(fedx_so_fy23, fedx_so_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_so_zoned_fy24 = pd.merge(fedx_so_fy24, fedx_so_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_so_zoned_fy25 = pd.merge(fedx_so_fy25, fedx_so_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_so_zoned_fy = pd.concat([fedx_so_zoned_fy23, fedx_so_zoned_fy24, fedx_so_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_so_zoned0 = fedx_so_zoned_fy[fedx_so_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_so_missing1 = fedx_so_zoned_fy[fedx_so_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_so_retry1 = fedx_so_missing1.merge(fedx_so_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_so_zoned1 = fedx_so_retry1[fedx_so_retry1['ZONE'].notnull()].copy()\n",
    "fedx_so_missing2 = fedx_so_retry1[fedx_so_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_so_retry2 = fedx_so_missing2.merge(fedx_so_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_so_zoned2 = fedx_so_retry2[fedx_so_retry2['ZONE'].notnull()].copy()\n",
    "fedx_so_missing3 = fedx_so_retry2[fedx_so_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_so_retry3 = fedx_so_missing3.merge(fedx_so_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_so_zoned = pd.concat([fedx_so_zoned0, fedx_so_zoned1, fedx_so_zoned2, fedx_so_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_so, fedx_so_fy23, fedx_so_fy24, fedx_so_fy25, fedx_so_rates_fy23, fedx_so_rates_fy24, fedx_so_rates_fy25\n",
    "del fedx_so_zoned_fy23, fedx_so_zoned_fy24, fedx_so_zoned_fy25, fedx_so_zoned_fy, fedx_so_zoned0, fedx_so_zoned1\n",
    "del fedx_so_zoned2, fedx_so_retry1, fedx_so_retry2, fedx_so_retry3, fedx_so_missing1, fedx_so_missing2, fedx_so_missing3\n",
    "\n",
    "print(f'FEDEX Standard Overnight Merge Results')\n",
    "print(f'Missing Zones: ',fedx_so_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_so_zoned))\n",
    "print(round(((fedx_so_zoned[\"ZONE\"].isna().sum() / len(fedx_so_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55433d5d-f6bb-48bc-8dd4-7f5fef29b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDEX Ground\n",
    "fedx_ground = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx Ground'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_ground_fy23 = fedx_ground[fedx_ground['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "fedx_ground_fy24 = fedx_ground[(fedx_ground['ACTUAL_PICKUP_DATE'] >= date_before) & (fedx_ground['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_ground_fy25 = fedx_ground[fedx_ground['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_ground_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'ground_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_ground_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'ground_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_ground_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'ground_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "fedx_ground['BILLED_WEIGHT'] = fedx_ground['BILLED_WEIGHT'].astype('float')\n",
    "fedx_ground['TOTAL_FREIGHT_AMOUNT'] = fedx_ground['TOTAL_FREIGHT_AMOUNT'].astype('float')\n",
    "fedx_ground_rates_fy23['FreightPrice'] = fedx_ground_rates_fy23['FreightPrice'].astype('float')\n",
    "fedx_ground_rates_fy23['WEIGHT'] = fedx_ground_rates_fy23['WEIGHT'].astype('float32')\n",
    "fedx_ground_rates_fy24['FreightPrice'] = fedx_ground_rates_fy24['FreightPrice'].astype('float')\n",
    "fedx_ground_rates_fy24['WEIGHT'] = fedx_ground_rates_fy24['WEIGHT'].astype('float')\n",
    "fedx_ground_rates_fy25['FreightPrice'] = fedx_ground_rates_fy25['FreightPrice'].astype('float')\n",
    "fedx_ground_rates_fy25['WEIGHT'] = fedx_ground_rates_fy25['WEIGHT'].astype('float')\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_ground_zoned_fy23 = pd.merge(fedx_ground_fy23, fedx_ground_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_ground_zoned_fy24 = pd.merge(fedx_ground_fy24, fedx_ground_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_ground_zoned_fy25 = pd.merge(fedx_ground_fy25, fedx_ground_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_ground_zoned_fy = pd.concat([fedx_ground_zoned_fy23, fedx_ground_zoned_fy24, fedx_ground_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_ground_zoned0 = fedx_ground_zoned_fy[fedx_ground_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_ground_missing1 = fedx_ground_zoned_fy[fedx_ground_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_ground_retry1 = fedx_ground_missing1.merge(fedx_ground_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_ground_zoned1 = fedx_ground_retry1[fedx_ground_retry1['ZONE'].notnull()].copy()\n",
    "fedx_ground_missing2 = fedx_ground_retry1[fedx_ground_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_ground_retry2 = fedx_ground_missing2.merge(fedx_ground_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_ground_zoned2 = fedx_ground_retry2[fedx_ground_retry2['ZONE'].notnull()].copy()\n",
    "fedx_ground_missing3 = fedx_ground_retry2[fedx_ground_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_ground_retry3 = fedx_ground_missing3.merge(fedx_ground_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_ground_zoned = pd.concat([fedx_ground_zoned0, fedx_ground_zoned1, fedx_ground_zoned2, fedx_ground_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_ground, fedx_ground_fy23, fedx_ground_fy24, fedx_ground_fy25, fedx_ground_rates_fy23, fedx_ground_rates_fy24, fedx_ground_rates_fy25\n",
    "del fedx_ground_zoned_fy23, fedx_ground_zoned_fy24, fedx_ground_zoned_fy25, fedx_ground_zoned_fy, fedx_ground_zoned0, fedx_ground_zoned1\n",
    "del fedx_ground_zoned2, fedx_ground_retry1, fedx_ground_retry2, fedx_ground_retry3, fedx_ground_missing1, fedx_ground_missing2, fedx_ground_missing3\n",
    "\n",
    "print(f'FEDEX Ground Merge Results')\n",
    "print(f'Missing Zones: ',fedx_ground_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_ground_zoned))\n",
    "print(round(((fedx_ground_zoned[\"ZONE\"].isna().sum() / len(fedx_ground_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a12548-1c89-4b61-bb65-c27149105e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDEX 2Day\n",
    "fedx_2d = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx 2Day'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_2d_fy23 = fedx_2d[fedx_2d['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "fedx_2d_fy24 = fedx_2d[(fedx_2d['ACTUAL_PICKUP_DATE'] >= date_before) & (fedx_2d['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_2d_fy25 = fedx_2d[fedx_2d['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_2d_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = '2d_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_2d_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = '2d_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_2d_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = '2d_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "fedx_2d['BILLED_WEIGHT'] = fedx_2d['BILLED_WEIGHT'].astype('float')\n",
    "fedx_2d['TOTAL_FREIGHT_AMOUNT'] = fedx_2d['TOTAL_FREIGHT_AMOUNT'].astype('float')\n",
    "fedx_2d_rates_fy23['FreightPrice'] = fedx_2d_rates_fy23['FreightPrice'].astype('float')\n",
    "fedx_2d_rates_fy23['WEIGHT'] = fedx_2d_rates_fy23['WEIGHT'].astype('float32')\n",
    "fedx_2d_rates_fy24['FreightPrice'] = fedx_2d_rates_fy24['FreightPrice'].astype('float')\n",
    "fedx_2d_rates_fy24['WEIGHT'] = fedx_2d_rates_fy24['WEIGHT'].astype('float')\n",
    "fedx_2d_rates_fy25['FreightPrice'] = fedx_2d_rates_fy25['FreightPrice'].astype('float')\n",
    "fedx_2d_rates_fy25['WEIGHT'] = fedx_2d_rates_fy25['WEIGHT'].astype('float')\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_2d_zoned_fy23 = pd.merge(fedx_2d_fy23, fedx_2d_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2d_zoned_fy24 = pd.merge(fedx_2d_fy24, fedx_2d_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2d_zoned_fy25 = pd.merge(fedx_2d_fy25, fedx_2d_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_2d_zoned_fy = pd.concat([fedx_2d_zoned_fy23, fedx_2d_zoned_fy24, fedx_2d_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_2d_zoned0 = fedx_2d_zoned_fy[fedx_2d_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_2d_missing1 = fedx_2d_zoned_fy[fedx_2d_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_2d_retry1 = fedx_2d_missing1.merge(fedx_2d_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2d_zoned1 = fedx_2d_retry1[fedx_2d_retry1['ZONE'].notnull()].copy()\n",
    "fedx_2d_missing2 = fedx_2d_retry1[fedx_2d_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_2d_retry2 = fedx_2d_missing2.merge(fedx_2d_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2d_zoned2 = fedx_2d_retry2[fedx_2d_retry2['ZONE'].notnull()].copy()\n",
    "fedx_2d_missing3 = fedx_2d_retry2[fedx_2d_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_2d_retry3 = fedx_2d_missing3.merge(fedx_2d_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_2d_zoned = pd.concat([fedx_2d_zoned0, fedx_2d_zoned1, fedx_2d_zoned2, fedx_2d_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_2d, fedx_2d_fy23, fedx_2d_fy24, fedx_2d_fy25, fedx_2d_rates_fy23, fedx_2d_rates_fy24, fedx_2d_rates_fy25\n",
    "del fedx_2d_zoned_fy23, fedx_2d_zoned_fy24, fedx_2d_zoned_fy25, fedx_2d_zoned_fy, fedx_2d_zoned0, fedx_2d_zoned1\n",
    "del fedx_2d_zoned2, fedx_2d_retry1, fedx_2d_retry2, fedx_2d_retry3, fedx_2d_missing1, fedx_2d_missing2, fedx_2d_missing3\n",
    "\n",
    "print(f'FEDEX 2Day Merge Results')\n",
    "print(f'Missing Zones: ',fedx_2d_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_2d_zoned))\n",
    "print(round(((fedx_2d_zoned[\"ZONE\"].isna().sum() / len(fedx_2d_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4b1d7-c188-41cd-9ca2-a4af24aba119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDEX First Overnight\n",
    "fedx_fo = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx First Overnight'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Before 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_before = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_fo_fy23 = fedx_fo[fedx_fo['ACTUAL_PICKUP_DATE'] < date_before].copy()\n",
    "fedx_fo_fy24 = fedx_fo[(fedx_fo['ACTUAL_PICKUP_DATE'] >= date_before) & (fedx_fo['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_fo_fy25 = fedx_fo[fedx_fo['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_fo_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'fo_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_fo_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'fo_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_fo_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'fo_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "fedx_fo['BILLED_WEIGHT'] = fedx_fo['BILLED_WEIGHT'].astype('float')\n",
    "fedx_fo['TOTAL_FREIGHT_AMOUNT'] = fedx_fo['TOTAL_FREIGHT_AMOUNT'].astype('float')\n",
    "fedx_fo_rates_fy23['FreightPrice'] = fedx_fo_rates_fy23['FreightPrice'].astype('float')\n",
    "fedx_fo_rates_fy23['WEIGHT'] = fedx_fo_rates_fy23['WEIGHT'].astype('float32')\n",
    "fedx_fo_rates_fy24['FreightPrice'] = fedx_fo_rates_fy24['FreightPrice'].astype('float')\n",
    "fedx_fo_rates_fy24['WEIGHT'] = fedx_fo_rates_fy24['WEIGHT'].astype('float')\n",
    "fedx_fo_rates_fy25['FreightPrice'] = fedx_fo_rates_fy25['FreightPrice'].astype('float')\n",
    "fedx_fo_rates_fy25['WEIGHT'] = fedx_fo_rates_fy25['WEIGHT'].astype('float')\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_fo_zoned_fy23 = pd.merge(fedx_fo_fy23, fedx_fo_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_fo_zoned_fy24 = pd.merge(fedx_fo_fy24, fedx_fo_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_fo_zoned_fy25 = pd.merge(fedx_fo_fy25, fedx_fo_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_fo_zoned_fy = pd.concat([fedx_fo_zoned_fy23, fedx_fo_zoned_fy24, fedx_fo_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_fo_zoned0 = fedx_fo_zoned_fy[fedx_fo_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_fo_missing1 = fedx_fo_zoned_fy[fedx_fo_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_fo_retry1 = fedx_fo_missing1.merge(fedx_fo_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_fo_zoned1 = fedx_fo_retry1[fedx_fo_retry1['ZONE'].notnull()].copy()\n",
    "fedx_fo_missing2 = fedx_fo_retry1[fedx_fo_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_fo_retry2 = fedx_fo_missing2.merge(fedx_fo_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_fo_zoned2 = fedx_fo_retry2[fedx_fo_retry2['ZONE'].notnull()].copy()\n",
    "fedx_fo_missing3 = fedx_fo_retry2[fedx_fo_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_fo_retry3 = fedx_fo_missing3.merge(fedx_fo_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_fo_zoned = pd.concat([fedx_fo_zoned0, fedx_fo_zoned1, fedx_fo_zoned2, fedx_fo_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_fo, fedx_fo_fy23, fedx_fo_fy24, fedx_fo_fy25, fedx_fo_rates_fy23, fedx_fo_rates_fy24, fedx_fo_rates_fy25\n",
    "del fedx_fo_zoned_fy23, fedx_fo_zoned_fy24, fedx_fo_zoned_fy25, fedx_fo_zoned_fy, fedx_fo_zoned0, fedx_fo_zoned1\n",
    "del fedx_fo_zoned2, fedx_fo_retry1, fedx_fo_retry2, fedx_fo_retry3, fedx_fo_missing1, fedx_fo_missing2, fedx_fo_missing3\n",
    "\n",
    "print(f'FEDEX First Overnight Merge Results')\n",
    "print(f'Missing Zones: ',fedx_fo_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_fo_zoned))\n",
    "print(round(((fedx_fo_zoned[\"ZONE\"].isna().sum() / len(fedx_fo_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be7695-aaac-4483-920a-c999e95deb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEDEX 2Day AM\n",
    "fedx_2dam = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx 2Day AM'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Be2damre 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_be2damre = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_2dam_fy23 = fedx_2dam[fedx_2dam['ACTUAL_PICKUP_DATE'] < date_be2damre].copy()\n",
    "fedx_2dam_fy24 = fedx_2dam[(fedx_2dam['ACTUAL_PICKUP_DATE'] >= date_be2damre) & (fedx_2dam['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_2dam_fy25 = fedx_2dam[fedx_2dam['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_2dam_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = '2dam_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_2dam_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = '2dam_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_2dam_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = '2dam_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "fedx_2dam['BILLED_WEIGHT'] = fedx_2dam['BILLED_WEIGHT'].astype('float')\n",
    "fedx_2dam['TOTAL_FREIGHT_AMOUNT'] = fedx_2dam['TOTAL_FREIGHT_AMOUNT'].astype('float')\n",
    "fedx_2dam_rates_fy23['FreightPrice'] = fedx_2dam_rates_fy23['FreightPrice'].astype('float')\n",
    "fedx_2dam_rates_fy23['WEIGHT'] = fedx_2dam_rates_fy23['WEIGHT'].astype('float32')\n",
    "fedx_2dam_rates_fy24['FreightPrice'] = fedx_2dam_rates_fy24['FreightPrice'].astype('float')\n",
    "fedx_2dam_rates_fy24['WEIGHT'] = fedx_2dam_rates_fy24['WEIGHT'].astype('float')\n",
    "fedx_2dam_rates_fy25['FreightPrice'] = fedx_2dam_rates_fy25['FreightPrice'].astype('float')\n",
    "fedx_2dam_rates_fy25['WEIGHT'] = fedx_2dam_rates_fy25['WEIGHT'].astype('float')\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_2dam_zoned_fy23 = pd.merge(fedx_2dam_fy23, fedx_2dam_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2dam_zoned_fy24 = pd.merge(fedx_2dam_fy24, fedx_2dam_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2dam_zoned_fy25 = pd.merge(fedx_2dam_fy25, fedx_2dam_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_2dam_zoned_fy = pd.concat([fedx_2dam_zoned_fy23, fedx_2dam_zoned_fy24, fedx_2dam_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_2dam_zoned0 = fedx_2dam_zoned_fy[fedx_2dam_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_2dam_missing1 = fedx_2dam_zoned_fy[fedx_2dam_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_2dam_retry1 = fedx_2dam_missing1.merge(fedx_2dam_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2dam_zoned1 = fedx_2dam_retry1[fedx_2dam_retry1['ZONE'].notnull()].copy()\n",
    "fedx_2dam_missing2 = fedx_2dam_retry1[fedx_2dam_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_2dam_retry2 = fedx_2dam_missing2.merge(fedx_2dam_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_2dam_zoned2 = fedx_2dam_retry2[fedx_2dam_retry2['ZONE'].notnull()].copy()\n",
    "fedx_2dam_missing3 = fedx_2dam_retry2[fedx_2dam_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_2dam_retry3 = fedx_2dam_missing3.merge(fedx_2dam_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_2dam_zoned = pd.concat([fedx_2dam_zoned0, fedx_2dam_zoned1, fedx_2dam_zoned2, fedx_2dam_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_2dam, fedx_2dam_fy23, fedx_2dam_fy24, fedx_2dam_fy25, fedx_2dam_rates_fy23, fedx_2dam_rates_fy24, fedx_2dam_rates_fy25\n",
    "del fedx_2dam_zoned_fy23, fedx_2dam_zoned_fy24, fedx_2dam_zoned_fy25, fedx_2dam_zoned_fy, fedx_2dam_zoned0, fedx_2dam_zoned1\n",
    "del fedx_2dam_zoned2, fedx_2dam_retry1, fedx_2dam_retry2, fedx_2dam_retry3, fedx_2dam_missing1, fedx_2dam_missing2, fedx_2dam_missing3\n",
    "\n",
    "print(f'FEDEX 2Day AM Merge Results')\n",
    "print(f'Missing Zones: ',fedx_2dam_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_2dam_zoned))\n",
    "print(round(((fedx_2dam_zoned[\"ZONE\"].isna().sum() / len(fedx_2dam_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ba8d7-bce7-40d2-adda-3b546a0c4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FedEx Express Saver\n",
    "fedx_es = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx Express Saver'].copy()\n",
    "\n",
    "#Splitting data by Pick-up dates: Beesre 10/10/23, 10/10/23-10/10/24, After 10/10/24\n",
    "date_beesre = pd.Timestamp('2023-10-10')\n",
    "date_after = pd.Timestamp('2024-10-10')\n",
    "\n",
    "fedx_es_fy23 = fedx_es[fedx_es['ACTUAL_PICKUP_DATE'] < date_beesre].copy()\n",
    "fedx_es_fy24 = fedx_es[(fedx_es['ACTUAL_PICKUP_DATE'] >= date_beesre) & (fedx_es['ACTUAL_PICKUP_DATE'] <= date_after)].copy()\n",
    "fedx_es_fy25 = fedx_es[fedx_es['ACTUAL_PICKUP_DATE'] > date_after].copy()\n",
    "\n",
    "#Loading Excel Sheets\n",
    "fedx_es_rates_fy23 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'es_rates_fy23').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_es_rates_fy24 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'es_rates_fy24').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "fedx_es_rates_fy25 = pd.read_excel('fedex_costs.xlsx', sheet_name = 'es_rates_fy25').melt(id_vars=\"WEIGHT\", var_name=\"ZONE\", value_name=\"FreightPrice\")\n",
    "\n",
    "fedx_es['BILLED_WEIGHT'] = fedx_es['BILLED_WEIGHT'].astype('float')\n",
    "fedx_es['TOTAL_FREIGHT_AMOUNT'] = fedx_es['TOTAL_FREIGHT_AMOUNT'].astype('float')\n",
    "fedx_es_rates_fy23['FreightPrice'] = fedx_es_rates_fy23['FreightPrice'].astype('float')\n",
    "fedx_es_rates_fy23['WEIGHT'] = fedx_es_rates_fy23['WEIGHT'].astype('float32')\n",
    "fedx_es_rates_fy24['FreightPrice'] = fedx_es_rates_fy24['FreightPrice'].astype('float')\n",
    "fedx_es_rates_fy24['WEIGHT'] = fedx_es_rates_fy24['WEIGHT'].astype('float')\n",
    "fedx_es_rates_fy25['FreightPrice'] = fedx_es_rates_fy25['FreightPrice'].astype('float')\n",
    "fedx_es_rates_fy25['WEIGHT'] = fedx_es_rates_fy25['WEIGHT'].astype('float')\n",
    "\n",
    "#Merging Sheets based on Pick-up Dates\n",
    "fedx_es_zoned_fy23 = pd.merge(fedx_es_fy23, fedx_es_rates_fy23, \n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_es_zoned_fy24 = pd.merge(fedx_es_fy24, fedx_es_rates_fy24,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_es_zoned_fy25 = pd.merge(fedx_es_fy25, fedx_es_rates_fy25,\n",
    "                                  left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_es_zoned_fy = pd.concat([fedx_es_zoned_fy23, fedx_es_zoned_fy24, fedx_es_zoned_fy25], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "fedx_es_zoned0 = fedx_es_zoned_fy[fedx_es_zoned_fy['ZONE'].notnull()].copy()\n",
    "fedx_es_missing1 = fedx_es_zoned_fy[fedx_es_zoned_fy['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "#Merging table with missing zones to all zone tables, than concat back to successful zones\n",
    "fedx_es_retry1 = fedx_es_missing1.merge(fedx_es_rates_fy25, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_es_zoned1 = fedx_es_retry1[fedx_es_retry1['ZONE'].notnull()].copy()\n",
    "fedx_es_missing2 = fedx_es_retry1[fedx_es_retry1['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_es_retry2 = fedx_es_missing2.merge(fedx_es_rates_fy24, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "fedx_es_zoned2 = fedx_es_retry2[fedx_es_retry2['ZONE'].notnull()].copy()\n",
    "fedx_es_missing3 = fedx_es_retry2[fedx_es_retry2['ZONE'].isnull()].drop(columns = [\"WEIGHT\", \"FreightPrice\", \"ZONE\"]).copy()\n",
    "\n",
    "fedx_es_retry3 = fedx_es_missing3.merge(fedx_es_rates_fy23, left_on = [\"BILLED_WEIGHT\", \"TOTAL_FREIGHT_AMOUNT\"], \n",
    "                                              right_on = [\"WEIGHT\", \"FreightPrice\"], how = \"left\")\n",
    "\n",
    "fedx_es_zoned = pd.concat([fedx_es_zoned0, fedx_es_zoned1, fedx_es_zoned2, fedx_es_retry3], ignore_index = True)\n",
    "\n",
    "#Deleting Uneeded Variables to Release Memory\n",
    "del fedx_es, fedx_es_fy23, fedx_es_fy24, fedx_es_fy25, fedx_es_rates_fy23, fedx_es_rates_fy24, fedx_es_rates_fy25\n",
    "del fedx_es_zoned_fy23, fedx_es_zoned_fy24, fedx_es_zoned_fy25, fedx_es_zoned_fy, fedx_es_zoned0, fedx_es_zoned1\n",
    "del fedx_es_zoned2, fedx_es_retry1, fedx_es_retry2, fedx_es_retry3, fedx_es_missing1, fedx_es_missing2, fedx_es_missing3\n",
    "\n",
    "print(f'FedEx Express Saver Merge Results')\n",
    "print(f'Missing Zones: ',fedx_es_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_es_zoned))\n",
    "print(round(((fedx_es_zoned[\"ZONE\"].isna().sum() / len(fedx_es_zoned))*100),2), f'% Zones Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e17bb-9088-45bc-978b-2fe66ce7627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FedEx Economy\n",
    "fedx_eco = fedx[fedx['SERVICE_LVL_CD_DESC'] == 'FedEx Economy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a0b58-d971-4655-8fde-42fa63226773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append all FedEx\n",
    "fedx_dfs = [fedx_hd_zoned, fedx_po_zoned, fedx_so_zoned, fedx_ground_zoned, fedx_2d_zoned, fedx_fo_zoned, fedx_2dam_zoned, fedx_es_zoned, fedx_eco]\n",
    "fedx_zoned = pd.concat(fedx_dfs, ignore_index = True)\n",
    "\n",
    "print(f'FedEx Merge Results')\n",
    "print(f'Missing Zones: ',fedx_zoned[\"ZONE\"].isna().sum())\n",
    "print(f'Total Rows: ', len(fedx_zoned))\n",
    "print(round(((fedx_zoned[\"ZONE\"].isna().sum() / len(fedx_zoned))*100),2), f'% Zones Missing')\n",
    "\n",
    "del fedx_hd_zoned, fedx_po_zoned, fedx_so_zoned, fedx_ground_zoned, fedx_2d_zoned, fedx_fo_zoned, fedx_2dam_zoned, fedx_es_zoned, fedx_eco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3fd32f-72ae-4199-a11a-0651dc91a3f7",
   "metadata": {},
   "source": [
    "## Zone Assignments - ZIP Code Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bcd91-8d53-4811-b91f-62a445ad915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recombine FEDEX and UPS Data\n",
    "data = pd.concat([fedx_zoned, upso_zoned], ignore_index = True).drop(columns = ([\"WEIGHT\", \"FreightPrice\"]))\n",
    "data = pd.concat([data, data_zoned], ignore_index = True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240c635-8183-4584-b099-8b8c5a7edff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Recombine FEDEX and UPS Data\n",
    "#data = pd.concat([fedx_zoned, upso_zoned], ignore_index = True).drop(columns = ([\"WEIGHT\", \"FreightPrice\"]))\n",
    "#data = pd.concat([data, data_zoned], ignore_index = True)\n",
    "\n",
    "#Seperating data where merge was sucessful and unsucessful\n",
    "data_zoned = data[data['ZONE'].notnull()].copy()\n",
    "data_missing = data[data['ZONE'].isnull()].drop(columns = [\"ZONE\"]).copy()\n",
    "\n",
    "#Creating table with unique ZIP/Zone Combinations\n",
    "zip_zone = data[['SHIPPER_ZIP', 'RECIPIENT_ZIP', 'ZONE']].drop_duplicates(subset=['SHIPPER_ZIP', 'RECIPIENT_ZIP']).dropna().reset_index(drop=True)\n",
    "\n",
    "#Merging unmached zone data matched by price with unique ZIP/Zone table\n",
    "data_zip_matched = pd.merge(data_missing, zip_zone, on = ['SHIPPER_ZIP', 'RECIPIENT_ZIP'], how = 'left')\n",
    "\n",
    "#Merging with Second ZIP-Zone Table (From CMOP Data)\n",
    "zips = pd.read_excel(\"ZIPs.xlsx\", sheet_name = \"ZIPS\")\n",
    "zips[['SHIPPER_ZIP', 'RECIPIENT_ZIP', 'ZONE']] = zips[['SHIPPER_ZIP', 'RECIPIENT_ZIP', 'ZONE']].astype('object')\n",
    "data_zip_matched_1 = data_zip_matched[data_zip_matched['ZONE'].notnull()]\n",
    "data_missing_1 = data_zip_matched[data_zip_matched['ZONE'].isnull()].drop(columns = [\"ZONE\"]).copy()\n",
    "data_zip_matched_2 = pd.merge(data_missing_1, zips, on = ['SHIPPER_ZIP', 'RECIPIENT_ZIP'], how = 'left')\n",
    "\n",
    "#Merging data matched by price with data matched by ZIP\n",
    "data = pd.concat([data_zoned, data_zip_matched_1, data_zip_matched_2], ignore_index = True)\n",
    "\n",
    "del zips, zip_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a713d-b213-42e2-a7fc-178e079021d5",
   "metadata": {},
   "source": [
    "## Zone Assignments - Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c5977-4972-4ff2-a382-657c73836cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.groupby('SERVICE_LVL_CD_DESC').apply(\n",
    "    lambda group: pd.Series({\n",
    "        'Counts': len(group),\n",
    "        '# of Missing ZONEs ': group['ZONE'].isna().sum(),\n",
    "        '% Zones Missing': round(((group['ZONE'].isna().mean()) * 100),2)})).reset_index()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de658fbc-8cb4-4281-a39e-3e7b07a1dfbd",
   "metadata": {},
   "source": [
    "# CMOP VS. TRANSCOM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e34c7c-3cf6-41c1-8b60-2360a5c07ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CMOP Account Data\n",
    "cmop_accounts = pd.read_excel('Transcom CMOP Account Data.xlsx', sheet_name = 'Sheet1')\n",
    "cmop_list = cmop_accounts['TRANSCOM Account Number'].tolist()\n",
    "\n",
    "#Creating a new TRANSCOM/CMOP Column\n",
    "data['TRANSCOM/CMOP'] = data['FREIGHT_PAYEE_ACCOUNT_NUMBER'].isin(cmop_list).map({True: 'CMOP', False: 'TRANSCOM'})\n",
    "del cmop_accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2162d2-85db-4d25-aba7-6ada67f4525f",
   "metadata": {},
   "source": [
    "# Final Cleaning & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003e758-0fab-4552-8311-21eb41636c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearrange Columns\n",
    "data = data[['REPORT_MONTH', 'SHIPPING_AGENCY_LVL_3', 'CHILD_NAME', 'CARRIER_SCAC', 'SHIPMENT_TRACKING_NUMBER',\n",
    " 'SHIPMENT_TRACKING_GROUP_ID', 'FREIGHT_PAYEE_ACCOUNT_NUMBER', 'LEAD_TRACKING_NUMBER', 'RESIDENTIAL_FLAG',\n",
    " 'RATE_SERVICE_FLAG', 'DELIVERY_STATUS_CODE', 'DELIVERY_STATUS_FLAG', 'DELAYS', 'SERVICE_LVL_CD_DESC', 'PACKAGE_TYPE',\n",
    " 'ACTUAL_PICKUP_DATE', 'ACTUAL_DELIVERY_DATE', 'CONTRACT_DELIVERY_DATE', 'INVOICE_DATE', 'SHIPPER_CITY_NAME',\n",
    " 'SHIPPER_STATE_PRVNC', 'SHIPPER_ZIP', 'RECIPIENT_CITY_NAME', 'RECIPIENT_STATE_PRVNC', 'RECIPIENT_ZIP', 'ZONE','NUM_OF_SHIPMENTS',\n",
    " 'NUM_OF_PACKAGES', 'PACKAGE_LENGTH', 'PACKAGE_HEIGHT', 'PACKAGE_WIDTH', 'BILLED_WEIGHT', 'ACTUAL_WEIGHT',\n",
    " 'TOTAL_SURCHARGE_AMOUNT', 'TOTAL_FREIGHT_AMOUNT', 'TOTAL_DISCOUNT_AMOUNT', 'TOTAL_NET_AMOUNT']]\n",
    "\n",
    "#Renaming columns\n",
    "cols_rn = {\n",
    " 'REPORT_MONTH':\"Report Month\", \n",
    " 'SHIPPING_AGENCY_LVL_3':'Shipping Agency Lvl 3', \n",
    " 'CHILD_NAME':'Child Name', \n",
    " 'CARRIER_SCAC':'Carrier', \n",
    " 'SHIPMENT_TRACKING_NUMBER':'Shipping Tracking #', \n",
    " 'SHIPMENT_TRACKING_GROUP_ID':\"Shipment Tracking Group ID\",\n",
    " 'FREIGHT_PAYEE_ACCOUNT_NUMBER':'Freight Payee Account Number',\n",
    " 'LEAD_TRACKING_NUMBER':'Lead Tracking #',\n",
    " 'RESIDENTIAL_FLAG':'Residential Flag',\n",
    " 'RATE_SERVICE_FLAG':'Rate Service Flag',\n",
    " 'DELIVERY_STATUS_CODE':'Delivery Status Code',\n",
    " 'DELIVERY_STATUS_FLAG':'Delivery Status Flag',\n",
    " 'DELAYS':'Delays', \n",
    " 'SERVICE_LVL_CD_DESC':'Service Level',\n",
    " 'PACKAGE_TYPE':'Package Type',\n",
    " 'ACTUAL_PICKUP_DATE':'Actual Pick-up Date',\n",
    " 'ACTUAL_DELIVERY_DATE':'Actual Delivery Date',\n",
    " 'CONTRACT_DELIVERY_DATE':'Contract Delivery Date', \n",
    " 'INVOICE_DATE':'Invoice Date', 'SHIPPER_CITY_NAME': 'Shipper City',\n",
    " 'SHIPPER_STATE_PRVNC': 'Shipper State', 'SHIPPER_ZIP':'Shipper Zip', 'RECIPIENT_CITY_NAME': 'Recipient City',\n",
    " 'RECIPIENT_STATE_PRVNC': 'Recipient State', 'RECIPIENT_ZIP':'Recipient Zip', 'NUM_OF_SHIPMENTS': '# of Shipments', \n",
    " 'NUM_OF_PACKAGES': '# of Packages', 'PACKAGE_LENGTH':'Length', 'PACKAGE_HEIGHT':'Height', 'PACKAGE_WIDTH':'Width',\n",
    " 'BILLED_WEIGHT':'Billed Weight', 'ACTUAL_WEIGHT':'Actual Weight', 'TOTAL_SURCHARGE_AMOUNT':'Surcharge Amount',\n",
    " 'TOTAL_FREIGHT_AMOUNT':'Freight Amount', 'TOTAL_DISCOUNT_AMOUNT':'Discount Amount','TOTAL_NET_AMOUNT':'Net Amount', 'ZONE':'Zone'\n",
    "}\n",
    "data = data.rename(columns = cols_rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fe036-9e41-4532-8abf-e11f32769dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Data\n",
    "output_path = os.path.join(output_dir, output_filename)  # Save to Output folder\n",
    "data.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
